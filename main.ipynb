{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40649efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade accelerate \"transformers[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb56818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\1.apps\\python\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fbb84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading local JSON files...\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Local Dataset Files ---\n",
    "print(\"Step 1: Loading local JSON files...\")\n",
    "try:\n",
    "    with open('./dataset/train.json', 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open('./dataset/dev.json', 'r') as f:\n",
    "        dev_data = json.load(f)\n",
    "    with open('./dataset/test.json', 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train.json', 'dev.json', and 'test.json' are in a 'dataset' folder.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a7abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying fix: Converting all 'qa.exe_ans' values to string for dataset compatibility.\n",
      "Data cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "# [This code should go in Cell 5, where the old data cleaning code was]\n",
    "\n",
    "# --- Correct Data Cleaning for Mixed Types ---\n",
    "# The 'qa.exe_ans' field contains both numbers (e.g., 94.0) and strings (e.g., 'yes').\n",
    "# The Hugging Face `datasets` library (using Arrow) tries to guess the column type\n",
    "# and fails when it sees this mix.\n",
    "# To fix this, we convert all 'exe_ans' values to strings *before* creating the dataset.\n",
    "# The official 'evaluate.py' script is designed to handle this, as it converts\n",
    "# strings back to numbers where appropriate during evaluation.\n",
    "\n",
    "print(\"Applying fix: Converting all 'qa.exe_ans' values to string for dataset compatibility.\")\n",
    "for dataset in [train_data, dev_data, test_data]:\n",
    "    for item in dataset:\n",
    "        # Check if 'qa' and 'exe_ans' exist to avoid errors\n",
    "        if 'qa' in item and 'exe_ans' in item['qa']:\n",
    "            # This ensures all values in this \"column\" have the same type (string)\n",
    "            item['qa']['exe_ans'] = str(item['qa']['exe_ans'])\n",
    "\n",
    "print(\"Data cleaning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7668094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a quick demonstration, we'll use a smaller subset.\n",
    "# For a real run, use the full datasets: train_data, dev_data, test_data\n",
    "train_subset = train_data[:800]\n",
    "dev_subset = dev_data[:100]\n",
    "test_subset = test_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefed7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of dictionaries to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_list(train_subset)\n",
    "dev_dataset = Dataset.from_list(dev_subset)\n",
    "test_dataset = Dataset.from_list(test_subset)\n",
    "\n",
    "# Combine them into a single DatasetDict\n",
    "finqa_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': dev_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01379a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 800 training samples, 100 validation samples, and 100 test samples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(train_dataset)} training samples, {len(dev_dataset)} validation samples, and {len(test_dataset)} test samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7a5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the structure of the first example from the training set. \n",
      "This shows all the keys and the format of their values that our `preprocess_function` will receive.\n",
      "{\n",
      "  \"pre_text\": [\n",
      "    \"interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .\",\n",
      "    \"if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .\",\n",
      "    \"foreign currency exposure as more fully described in note 2i .\",\n",
      "    \"in the notes to consolidated financial statements contained in item 8 of this annual report on form 10-k , we regularly hedge our non-u.s .\",\n",
      "    \"dollar-based exposures by entering into forward foreign currency exchange contracts .\",\n",
      "    \"the terms of these contracts are for periods matching the duration of the underlying exposure and generally range from one month to twelve months .\",\n",
      "    \"currently , our largest foreign currency exposure is the euro , primarily because our european operations have the highest proportion of our local currency denominated expenses .\",\n",
      "    \"relative to foreign currency exposures existing at october 31 , 2009 and november 1 , 2008 , a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates over the course of the year would not expose us to significant losses in earnings or cash flows because we hedge a high proportion of our year-end exposures against fluctuations in foreign currency exchange rates .\",\n",
      "    \"the market risk associated with our derivative instruments results from currency exchange rate or interest rate movements that are expected to offset the market risk of the underlying transactions , assets and liabilities being hedged .\",\n",
      "    \"the counterparties to the agreements relating to our foreign exchange instruments consist of a number of major international financial institutions with high credit ratings .\",\n",
      "    \"we do not believe that there is significant risk of nonperformance by these counterparties because we continually monitor the credit ratings of such counterparties .\",\n",
      "    \"while the contract or notional amounts of derivative financial instruments provide one measure of the volume of these transactions , they do not represent the amount of our exposure to credit risk .\",\n",
      "    \"the amounts potentially subject to credit risk ( arising from the possible inability of counterparties to meet the terms of their contracts ) are generally limited to the amounts , if any , by which the counterparties 2019 obligations under the contracts exceed our obligations to the counterparties .\",\n",
      "    \"the following table illustrates the effect that a 10% ( 10 % ) unfavorable or favorable movement in foreign currency exchange rates , relative to the u.s .\",\n",
      "    \"dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .\"\n",
      "  ],\n",
      "  \"post_text\": [\n",
      "    \"fair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability ) .\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \"$ 20132 $ ( 9457 ) fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability .\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \".\",\n",
      "    \"$ ( 6781 ) $ ( 38294 ) the calculation assumes that each exchange rate would change in the same direction relative to the u.s .\",\n",
      "    \"dollar .\",\n",
      "    \"in addition to the direct effects of changes in exchange rates , such changes typically affect the volume of sales or the foreign currency sales price as competitors 2019 products become more or less attractive .\",\n",
      "    \"our sensitivity analysis of the effects of changes in foreign currency exchange rates does not factor in a potential change in sales levels or local currency selling prices. .\"\n",
      "  ],\n",
      "  \"filename\": \"ADI/2009/page_49.pdf\",\n",
      "  \"table_ori\": [\n",
      "    [\n",
      "      \"\",\n",
      "      \"October 31, 2009\",\n",
      "      \"November 1, 2008\"\n",
      "    ],\n",
      "    [\n",
      "      \"Fair value of forward exchange contracts asset (liability)\",\n",
      "      \"$6,427\",\n",
      "      \"$(23,158)\"\n",
      "    ],\n",
      "    [\n",
      "      \"Fair value of forward exchange contracts after a 10% unfavorable movement in foreign currency exchange rates asset (liability)\",\n",
      "      \"$20,132\",\n",
      "      \"$(9,457)\"\n",
      "    ],\n",
      "    [\n",
      "      \"Fair value of forward exchange contracts after a 10% favorable movement in foreign currency exchange rates liability\",\n",
      "      \"$(6,781)\",\n",
      "      \"$(38,294)\"\n",
      "    ]\n",
      "  ],\n",
      "  \"table\": [\n",
      "    [\n",
      "      \"\",\n",
      "      \"october 31 2009\",\n",
      "      \"november 1 2008\"\n",
      "    ],\n",
      "    [\n",
      "      \"fair value of forward exchange contracts asset ( liability )\",\n",
      "      \"$ 6427\",\n",
      "      \"$ -23158 ( 23158 )\"\n",
      "    ],\n",
      "    [\n",
      "      \"fair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability )\",\n",
      "      \"$ 20132\",\n",
      "      \"$ -9457 ( 9457 )\"\n",
      "    ],\n",
      "    [\n",
      "      \"fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability\",\n",
      "      \"$ -6781 ( 6781 )\",\n",
      "      \"$ -38294 ( 38294 )\"\n",
      "    ]\n",
      "  ],\n",
      "  \"qa\": {\n",
      "    \"ann_table_rows\": [],\n",
      "    \"ann_text_rows\": [\n",
      "      1\n",
      "    ],\n",
      "    \"answer\": \"380\",\n",
      "    \"exe_ans\": \"3.8\",\n",
      "    \"explanation\": \"\",\n",
      "    \"gold_inds\": {\n",
      "      \"table_0\": null,\n",
      "      \"table_1\": null,\n",
      "      \"table_10\": null,\n",
      "      \"table_11\": null,\n",
      "      \"table_12\": null,\n",
      "      \"table_13\": null,\n",
      "      \"table_15\": null,\n",
      "      \"table_2\": null,\n",
      "      \"table_3\": null,\n",
      "      \"table_4\": null,\n",
      "      \"table_5\": null,\n",
      "      \"table_6\": null,\n",
      "      \"table_7\": null,\n",
      "      \"table_8\": null,\n",
      "      \"table_9\": null,\n",
      "      \"text_0\": null,\n",
      "      \"text_1\": \"if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .\",\n",
      "      \"text_10\": null,\n",
      "      \"text_11\": null,\n",
      "      \"text_110\": null,\n",
      "      \"text_111\": null,\n",
      "      \"text_12\": null,\n",
      "      \"text_13\": null,\n",
      "      \"text_14\": null,\n",
      "      \"text_15\": null,\n",
      "      \"text_16\": null,\n",
      "      \"text_17\": null,\n",
      "      \"text_18\": null,\n",
      "      \"text_19\": null,\n",
      "      \"text_2\": null,\n",
      "      \"text_20\": null,\n",
      "      \"text_21\": null,\n",
      "      \"text_22\": null,\n",
      "      \"text_23\": null,\n",
      "      \"text_24\": null,\n",
      "      \"text_25\": null,\n",
      "      \"text_26\": null,\n",
      "      \"text_27\": null,\n",
      "      \"text_28\": null,\n",
      "      \"text_29\": null,\n",
      "      \"text_3\": null,\n",
      "      \"text_30\": null,\n",
      "      \"text_31\": null,\n",
      "      \"text_32\": null,\n",
      "      \"text_33\": null,\n",
      "      \"text_34\": null,\n",
      "      \"text_37\": null,\n",
      "      \"text_39\": null,\n",
      "      \"text_4\": null,\n",
      "      \"text_40\": null,\n",
      "      \"text_45\": null,\n",
      "      \"text_5\": null,\n",
      "      \"text_54\": null,\n",
      "      \"text_6\": null,\n",
      "      \"text_7\": null,\n",
      "      \"text_8\": null,\n",
      "      \"text_9\": null,\n",
      "      \"text_94\": null,\n",
      "      \"text_96\": null\n",
      "    },\n",
      "    \"model_input\": [\n",
      "      [\n",
      "        \"text_0\",\n",
      "        \"interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .\"\n",
      "      ],\n",
      "      [\n",
      "        \"text_1\",\n",
      "        \"if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .\"\n",
      "      ],\n",
      "      [\n",
      "        \"text_14\",\n",
      "        \"dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .\"\n",
      "      ]\n",
      "    ],\n",
      "    \"program\": \"divide(100, 100), divide(3.8, #0)\",\n",
      "    \"program_re\": \"divide(3.8, divide(100, 100))\",\n",
      "    \"question\": \"what is the the interest expense in 2009?\",\n",
      "    \"steps\": [\n",
      "      {\n",
      "        \"arg1\": \"100\",\n",
      "        \"arg2\": \"100\",\n",
      "        \"op\": \"divide1-1\",\n",
      "        \"res\": \"1%\"\n",
      "      },\n",
      "      {\n",
      "        \"arg1\": \"3.8\",\n",
      "        \"arg2\": \"#0\",\n",
      "        \"op\": \"divide1-2\",\n",
      "        \"res\": \"380\"\n",
      "      }\n",
      "    ],\n",
      "    \"tfidftopn\": {\n",
      "      \"table_1\": null,\n",
      "      \"table_10\": null,\n",
      "      \"table_11\": null,\n",
      "      \"table_12\": null,\n",
      "      \"table_13\": null,\n",
      "      \"table_16\": null,\n",
      "      \"table_18\": null,\n",
      "      \"table_2\": null,\n",
      "      \"table_3\": null,\n",
      "      \"table_4\": null,\n",
      "      \"table_5\": null,\n",
      "      \"table_6\": null,\n",
      "      \"table_7\": null,\n",
      "      \"table_8\": null,\n",
      "      \"table_9\": null,\n",
      "      \"text_0\": \"interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .\",\n",
      "      \"text_1\": null,\n",
      "      \"text_10\": null,\n",
      "      \"text_103\": null,\n",
      "      \"text_11\": null,\n",
      "      \"text_112\": null,\n",
      "      \"text_12\": null,\n",
      "      \"text_13\": null,\n",
      "      \"text_132\": null,\n",
      "      \"text_14\": \"dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .\",\n",
      "      \"text_15\": null,\n",
      "      \"text_16\": null,\n",
      "      \"text_17\": null,\n",
      "      \"text_18\": null,\n",
      "      \"text_19\": null,\n",
      "      \"text_2\": null,\n",
      "      \"text_20\": null,\n",
      "      \"text_21\": null,\n",
      "      \"text_22\": null,\n",
      "      \"text_23\": null,\n",
      "      \"text_24\": null,\n",
      "      \"text_25\": null,\n",
      "      \"text_26\": null,\n",
      "      \"text_27\": null,\n",
      "      \"text_28\": null,\n",
      "      \"text_29\": null,\n",
      "      \"text_3\": null,\n",
      "      \"text_30\": null,\n",
      "      \"text_31\": null,\n",
      "      \"text_32\": null,\n",
      "      \"text_34\": null,\n",
      "      \"text_35\": null,\n",
      "      \"text_36\": null,\n",
      "      \"text_37\": null,\n",
      "      \"text_38\": null,\n",
      "      \"text_4\": null,\n",
      "      \"text_5\": null,\n",
      "      \"text_51\": null,\n",
      "      \"text_52\": null,\n",
      "      \"text_6\": null,\n",
      "      \"text_68\": null,\n",
      "      \"text_7\": null,\n",
      "      \"text_8\": null,\n",
      "      \"text_9\": null,\n",
      "      \"text_92\": null\n",
      "    }\n",
      "  },\n",
      "  \"id\": \"ADI/2009/page_49.pdf-1\",\n",
      "  \"table_retrieved\": [\n",
      "    {\n",
      "      \"ind\": \"table_1\",\n",
      "      \"score\": -0.6207679510116577\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"table_2\",\n",
      "      \"score\": -0.8948984742164612\n",
      "    }\n",
      "  ],\n",
      "  \"text_retrieved\": [\n",
      "    {\n",
      "      \"ind\": \"text_1\",\n",
      "      \"score\": 1.251369595527649\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_0\",\n",
      "      \"score\": 0.6589734554290771\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_14\",\n",
      "      \"score\": -0.1914736032485962\n",
      "    }\n",
      "  ],\n",
      "  \"table_retrieved_all\": [\n",
      "    {\n",
      "      \"ind\": \"table_1\",\n",
      "      \"score\": -0.6207679510116577\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"table_2\",\n",
      "      \"score\": -0.8948984742164612\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"table_3\",\n",
      "      \"score\": -1.2129878997802734\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"table_0\",\n",
      "      \"score\": -2.9782934188842773\n",
      "    }\n",
      "  ],\n",
      "  \"text_retrieved_all\": [\n",
      "    {\n",
      "      \"ind\": \"text_1\",\n",
      "      \"score\": 1.251369595527649\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_0\",\n",
      "      \"score\": 0.6589734554290771\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_14\",\n",
      "      \"score\": -0.1914736032485962\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_47\",\n",
      "      \"score\": -1.0945320129394531\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_24\",\n",
      "      \"score\": -1.4916260242462158\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_12\",\n",
      "      \"score\": -1.5615578889846802\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_15\",\n",
      "      \"score\": -1.572263479232788\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_5\",\n",
      "      \"score\": -1.6337369680404663\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_3\",\n",
      "      \"score\": -1.678298830986023\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_6\",\n",
      "      \"score\": -1.6905218362808228\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_46\",\n",
      "      \"score\": -1.9114893674850464\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_7\",\n",
      "      \"score\": -1.914547324180603\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_8\",\n",
      "      \"score\": -1.955027461051941\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_49\",\n",
      "      \"score\": -2.0304598808288574\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_13\",\n",
      "      \"score\": -2.0383174419403076\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_10\",\n",
      "      \"score\": -2.112241268157959\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_11\",\n",
      "      \"score\": -2.1439552307128906\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_4\",\n",
      "      \"score\": -2.2258567810058594\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_48\",\n",
      "      \"score\": -2.409395694732666\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_9\",\n",
      "      \"score\": -2.6092159748077393\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_2\",\n",
      "      \"score\": -2.6313436031341553\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_16\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_17\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_18\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_19\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_20\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_21\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_22\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_23\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_25\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_26\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_27\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_28\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_29\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_30\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_31\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_32\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_33\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_34\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_35\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_36\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_37\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_38\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_39\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_40\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_41\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_42\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_43\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_44\",\n",
      "      \"score\": -2.932347536087036\n",
      "    },\n",
      "    {\n",
      "      \"ind\": \"text_45\",\n",
      "      \"score\": -2.932347536087036\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Below is the structure of the first example from the training set. \\nThis shows all the keys and the format of their values that our `preprocess_function` will receive.\")\n",
    "# Access the first example directly from the Hugging Face Dataset object\n",
    "first_example = finqa_dataset['train'][0]\n",
    "# Use json.dumps for pretty-printing the dictionary\n",
    "print(json.dumps(first_example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e5656",
   "metadata": {},
   "source": [
    "This code snippet **prepares the FinQA dataset for a T5 (Text-to-Text Transfer Transformer) model.**\n",
    "\n",
    "Here's a brief explanation:\n",
    "\n",
    "1.  **Loads Tokenizer:** It initializes a `T5Tokenizer` for the \"t5-small\" model, which is essential for converting text into numerical inputs that a T5 model can understand.\n",
    "2.  **`preprocess_function`:** This function takes raw FinQA examples (containing questions, pre/post text, tables, and reasoning programs) and transforms them into:\n",
    "    *   **Input Strings:** It linearizes the question, pre-text, post-text, and tabular data into a single, structured input string, prepending \"finqa: \" as a task-specific prefix.\n",
    "    *   **Target Strings:** It extracts the reasoning program as the desired output string.\n",
    "3.  **Tokenization:** Both the input and target strings are then tokenized using the T5 tokenizer, padded, and truncated to specific maximum lengths (1024 for inputs, 128 for targets). The tokenized targets are stored as `labels` in the output dictionary.\n",
    "4.  **Applies to Dataset:** Finally, the `preprocess_function` is applied to the entire `finqa_dataset` using the `map` method, processing data in batches and removing original columns to prepare the dataset for direct use in training a T5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1321af54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Preparing data for T5 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f426d0e4f647a3a022a75d7e30601e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\1.apps\\python\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8151e4ff3cf422aaf30889a7b81adef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\1.apps\\python\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015d2e7c84d1476eab76028842cacba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\1.apps\\python\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Data Preparation ---\n",
    "print(\"\\nStep 2: Preparing data for T5 model...\")\n",
    "\n",
    "MODEL_NAME = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Prepares the FinQA dataset for a T5 model.\"\"\"\n",
    "    \n",
    "    # The 'examples' parameter is a dictionary with keys like 'pre_text', 'post_text', etc.\n",
    "    # and values that are lists.\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(examples['id'])):\n",
    "        # Construct the input string\n",
    "        question = examples['qa'][i]['question']\n",
    "        pre_text = \" \".join(examples['pre_text'][i])\n",
    "        post_text = \" \".join(examples['post_text'][i])\n",
    "        \n",
    "        # Linearize the table using pandas for a clean string representation\n",
    "        table_data = examples['table'][i]\n",
    "        if table_data:\n",
    "            df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "            table_str = df.to_string(index=False)\n",
    "        else:\n",
    "            table_str = \"\"\n",
    "\n",
    "        # Combine all parts for the model's input\n",
    "        # We prepend \"finqa: \" as a task-specific prefix\n",
    "        input_text = f\"finqa: question: {question} pre_text: {pre_text} table: {table_str} post_text: {post_text}\"\n",
    "        inputs.append(input_text)\n",
    "\n",
    "        # The target for the model is the reasoning program\n",
    "        program = examples['qa'][i]['program']\n",
    "        targets.append(program)\n",
    "        \n",
    "    # Tokenize the processed inputs and targets\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the preprocessing function to the entire dataset\n",
    "tokenized_datasets = finqa_dataset.map(preprocess_function, batched=True, remove_columns=finqa_dataset['train'].column_names)\n",
    "print(\"Data preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1951f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a0321b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    # --- 3. Model Training ---\n",
    "    print(\"\\nStep 3: Training the T5 model...\")\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./finqa_t5_local_model\",\n",
    "        num_train_epochs=5,                # Increase for better performance\n",
    "        per_device_train_batch_size=4,     # Adjust based on your GPU memory\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=200,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\" # Disable wandb/tensorboard logging for this simple example\n",
    "    )\n",
    "\n",
    "    # Create the Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Save the final best model\n",
    "    trainer.save_model(\"./finqa_t5_final_model\")\n",
    "    print(\"Best model saved to ./finqa_t5_final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090af7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Generating predictions ready for 'evaluate.py'...\n",
      "Attempting to load model from: E:\\1.apps\\obsidian_folder\\Research\\Research_code\\FinQA\\finqa_t5_final_model\n",
      "Model loaded successfully!\n",
      "'predictions_final.json' created successfully in the correct format.\n",
      "\n",
      "--- DETAILED DEBUGGING OF FIRST 3 SAMPLES ---\n",
      "\n",
      "--- Comparing Sample ID: ETR/2016/page_23.pdf-2 ---\n",
      "Question: what is the net change in net revenue during 2015 for entergy corporation?\n",
      "  GOLD Program:      ['subtract(', '5829', '5735', ')', 'EOF']\n",
      "  PREDICTED Program: ['subtract(', '5735', '5829', ')', 'EOF']\n",
      "  GOLD Answer:       94.0\n",
      "  => Program Structure: MISMATCH.\n",
      "\n",
      "--- Comparing Sample ID: INTC/2015/page_41.pdf-4 ---\n",
      "Question: what percentage of total facilities as measured in square feet are leased?\n",
      "  GOLD Program:      ['divide(', '8.1', '56.0', ')', 'EOF']\n",
      "  PREDICTED Program: ['divide(', '2.1', '6.0', ')', 'EOF']\n",
      "  GOLD Answer:       0.14464\n",
      "  => Program Structure: MISMATCH.\n",
      "\n",
      "--- Comparing Sample ID: ADI/2011/page_61.pdf-2 ---\n",
      "Question: what is the percentage change in cash flow hedges in 2011 compare to the 2010?\n",
      "  GOLD Program:      ['subtract(', '153.7', '139.9', ')', 'divide(', '#0', '139.9', ')', 'EOF']\n",
      "  PREDICTED Program: ['divide(', '1.4', '42.1', ')', 'EOF']\n",
      "  GOLD Answer:       0.09864\n",
      "  => Program Structure: MISMATCH.\n",
      "\n",
      "--- END OF DETAILED DEBUGGING ---\n",
      "\n",
      "Step 5: Running the official evaluation script...\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Output from script:\n",
      "All:  100\n",
      "Exe acc:  0.0\n",
      "Prog acc:  0.0\n",
      "\n",
      "Evaluation script completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "# --- Step 4: Generate Predictions in the Correct Format ---\n",
    "print(\"\\nStep 4: Generating predictions ready for 'evaluate.py'...\")\n",
    "\n",
    "# IMPORTANT: This is the official tokenization logic from evaluate.py\n",
    "def correct_program_tokenization(original_program):\n",
    "    \"\"\"\n",
    "    This tokenizer is copied from the official evaluate.py script to ensure\n",
    "    100% format compatibility.\n",
    "    \"\"\"\n",
    "    if not isinstance(original_program, str):\n",
    "        return ['EOF']\n",
    "    original_program = original_program.split(', ')\n",
    "    program = []\n",
    "    for tok in original_program:\n",
    "        cur_tok = ''\n",
    "        for c in tok:\n",
    "            if c == ')':\n",
    "                if cur_tok != '': program.append(cur_tok)\n",
    "                cur_tok = ''\n",
    "            cur_tok += c\n",
    "            if c in ['(', ')']:\n",
    "                program.append(cur_tok)\n",
    "                cur_tok = ''\n",
    "        if cur_tok != '': program.append(cur_tok)\n",
    "    program.append('EOF')\n",
    "    return program\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "base_project_dir = r\"E:\\1.apps\\obsidian_folder\\Research\\Research_code\\FinQA\" # <--- ADJUST THIS LINE\n",
    "\n",
    "# Define the name of the folder containing your saved model\n",
    "model_folder_name = \"finqa_t5_final_model\"\n",
    "\n",
    "# Construct the full, absolute path to the model directory using os.path.join\n",
    "# This function intelligently handles OS-specific path separators.\n",
    "model_load_path = os.path.join(base_project_dir, model_folder_name)\n",
    "\n",
    "print(f\"Attempting to load model from: {model_load_path}\")\n",
    "\n",
    "try:\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\n",
    "        model_load_path,           # Pass the correctly constructed local path\n",
    "        local_files_only=True,     # Ensure it only looks for local files\n",
    "        force_download=False       # Explicitly prevent download attempts\n",
    "    ).to(device)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: Failed to load model. Please check the path and folder contents.\")\n",
    "    print(f\"Detailed error: {e}\")\n",
    "    print(f\"The path attempted was: {model_load_path}\")\n",
    "    print(\"Make sure that directory contains files like 'pytorch_model.bin', 'config.json', 'tokenizer.json', etc.\")\n",
    "    exit() # Exit if model loading fails, as subsequent steps will also fail\n",
    "\n",
    "predictions_for_eval = []\n",
    "\n",
    "# We use the original test_dataset to access all necessary fields\n",
    "for item in test_dataset:\n",
    "    # Prepare input for the model\n",
    "    question = item['qa']['question']\n",
    "    pre_text = \" \".join(item['pre_text'])\n",
    "    post_text = \" \".join(item['post_text'])\n",
    "    table_data = item['table']\n",
    "    table_str = pd.DataFrame(table_data[1:], columns=table_data[0]).to_string(index=False) if table_data else \"\"\n",
    "    input_text = f\"finqa: question: {question} pre_text: {pre_text} table: {table_str} post_text: {post_text}\"\n",
    "    \n",
    "    # Generate the program string from the model\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True).input_ids.to(device)\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    predicted_program_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Tokenize the generated string into the required list format\n",
    "    tokenized_program_list = correct_program_tokenization(predicted_program_string)\n",
    "    \n",
    "    # Create the prediction entry with the correct key (\"predicted\") and format\n",
    "    prediction_entry = {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"predicted\": tokenized_program_list # This is the crucial part\n",
    "    }\n",
    "    predictions_for_eval.append(prediction_entry)\n",
    "\n",
    "# Save the correctly formatted predictions to a file\n",
    "output_filename = 'predictions_final.json'\n",
    "with open(output_filename, 'w') as f:\n",
    "    json.dump(predictions_for_eval, f, indent=4)\n",
    "print(f\"'{output_filename}' created successfully in the correct format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e04ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exporting detailed comparison for all test samples ---\n",
      "Comparison file 'model_predictions_comparison.txt' has been created successfully.\n",
      "You can now open this file to inspect all predictions side-by-side.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 4.5: Export Detailed Comparison File for All Test Samples ---\n",
    "print(\"\\n--- Exporting detailed comparison for all test samples ---\")\n",
    "\n",
    "# Define the output file name\n",
    "comparison_filename = \"model_predictions_comparison.txt\"\n",
    "\n",
    "# For easy lookup, create a dictionary of the gold standard test data by ID\n",
    "gold_data_map = {item['id']: item for item in test_dataset}\n",
    "\n",
    "# Use a list to build the file content for efficiency\n",
    "output_lines = []\n",
    "output_lines.append(\"=\"*80)\n",
    "output_lines.append(\"         MODEL PREDICTION vs. GOLD STANDARD COMPARISON\")\n",
    "output_lines.append(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# Loop through ALL of your model's predictions\n",
    "for i, pred_item in enumerate(predictions_for_eval):\n",
    "    pred_id = pred_item['id']\n",
    "    predicted_program_list = pred_item['predicted']\n",
    "\n",
    "    # Find the corresponding gold standard data point\n",
    "    if pred_id in gold_data_map:\n",
    "        gold_item = gold_data_map[pred_id]\n",
    "        gold_program_string = gold_item['qa']['program']\n",
    "        \n",
    "        # IMPORTANT: Tokenize the gold program in the exact same way\n",
    "        # as the prediction for a fair comparison.\n",
    "        gold_program_list = correct_program_tokenization(gold_program_string)\n",
    "        gold_answer = gold_item['qa']['exe_ans']\n",
    "\n",
    "        # Determine if the programs match\n",
    "        is_match = (predicted_program_list == gold_program_list)\n",
    "        match_status = \"MATCH!\" if is_match else \"MISMATCH\"\n",
    "\n",
    "        # Append the formatted comparison to our list of lines\n",
    "        output_lines.append(f\"--- SAMPLE {i+1}/{len(predictions_for_eval)} | ID: {pred_id} ---\")\n",
    "        output_lines.append(f\"Question: {gold_item['qa']['question']}\")\n",
    "        output_lines.append(f\"  GOLD Program:      {gold_program_list}\")\n",
    "        output_lines.append(f\"  PREDICTED Program: {predicted_program_list}\")\n",
    "        output_lines.append(f\"  GOLD Answer:       {gold_answer}\")\n",
    "        output_lines.append(f\"  => Program Structure: {match_status}\")\n",
    "        output_lines.append(\"-\" * 50 + \"\\n\") # Add a separator for readability\n",
    "\n",
    "    else:\n",
    "        output_lines.append(f\"[Warning] Could not find gold data for predicted ID: {pred_id}\\n\")\n",
    "\n",
    "# Write all the collected lines to the file at once\n",
    "with open(comparison_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\".join(output_lines))\n",
    "\n",
    "print(f\"Comparison file '{comparison_filename}' has been created successfully.\")\n",
    "print(\"You can now open this file to inspect all predictions side-by-side.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 5: Run the Unchanged `evaluate.py` Script ---\n",
    "print(f\"\\nStep 5: Running the official evaluation script...\")\n",
    "gold_standard_file = './dataset/test.json'\n",
    "evaluation_script = './code/evaluate/evaluate.py' # This is evaluate.py in this environment\n",
    "\n",
    "if os.path.exists(gold_standard_file):\n",
    "    command = [\"python\", evaluation_script, output_filename, gold_standard_file]\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    if result.stdout:\n",
    "        print(\"Output from script:\")\n",
    "        print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"Errors from script (if any):\")\n",
    "        print(result.stderr)\n",
    "    if result.returncode == 0:\n",
    "        print(\"Evaluation script completed successfully.\")\n",
    "    else:\n",
    "        print(f\"Evaluation script failed with exit code: {result.returncode}\")\n",
    "else:\n",
    "    print(f\"\\nError: Gold standard file not found at '{gold_standard_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22fccd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "     RUNNING A SUPER SIMPLE FINQA-STYLE SANITY CHECK\n",
      "============================================================\n",
      "This test checks if the fine-tuned model has learned the most basic\n",
      "structure of the FinQA task: creating a simple program.\n",
      "\n",
      "[INFO] Feeding this input to the model:\n",
      "'finqa: question: What is the total of the first and second values? pre_text: The first value is 50. The second value is 25. table:  post_text: '\n",
      "\n",
      "--- RESULTS ---\n",
      "  [EXPECTED]: add(50, 25)\n",
      "  [MODEL'S ACTUAL OUTPUT]: duplicate\n",
      "------------------------------\n",
      "\n",
      "[ANALYSIS]: FAILED. The model did not produce the correct program for this trivial case.\n",
      "If this fails after training, it suggests a problem with the training process itself, such as:\n",
      "  - Not enough training data or epochs (the model is still severely undertrained).\n",
      "  - The learning rate is too high or too low, preventing effective learning.\n",
      "  - A subtle bug in the `preprocess_function` is creating bad training examples.\n",
      "\n",
      "============================================================\n",
      "      FINQA SANITY CHECK COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Super Simple FINQA-Style Sanity Check ---\n",
    "# This should be run AFTER the model has been fine-tuned.\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"     RUNNING A SUPER SIMPLE FINQA-STYLE SANITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(\"This test checks if the fine-tuned model has learned the most basic\")\n",
    "print(\"structure of the FinQA task: creating a simple program.\")\n",
    "\n",
    "# 1. Define an extremely simple FinQA-style input\n",
    "# The context is minimal and the numbers are obvious.\n",
    "simple_question = \"What is the total of the first and second values?\"\n",
    "simple_pre_text = \"The first value is 50. The second value is 25.\"\n",
    "simple_table_str = \"\" # No table\n",
    "simple_post_text = \"\" # No post_text\n",
    "\n",
    "# 2. Define the expected, perfect program output\n",
    "expected_program = \"add(50, 25)\"\n",
    "\n",
    "# 3. Construct the input string in the exact FinQA format\n",
    "input_text = f\"finqa: question: {simple_question} pre_text: {simple_pre_text} table: {simple_table_str} post_text: {simple_post_text}\"\n",
    "\n",
    "print(f\"\\n[INFO] Feeding this input to the model:\\n'{input_text}'\")\n",
    "\n",
    "# 4. Use the fine-tuned model to generate the program\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "outputs = model.generate(input_ids, max_length=128)\n",
    "predicted_program_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 5. Show the results\n",
    "print(\"\\n--- RESULTS ---\")\n",
    "print(f\"  [EXPECTED]: {expected_program}\")\n",
    "print(f\"  [MODEL'S ACTUAL OUTPUT]: {predicted_program_string}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 6. Analyze the result\n",
    "# We use .strip() to ignore any accidental leading/trailing whitespace\n",
    "if predicted_program_string.strip() == expected_program:\n",
    "    print(\"\\n[ANALYSIS]: SUCCESS! The fine-tuned model passed the simplest FinQA test.\")\n",
    "    print(\"This is a strong positive signal that the training process was effective and\")\n",
    "    print(\"the model is learning to generate programs in the correct format.\")\n",
    "else:\n",
    "    print(\"\\n[ANALYSIS]: FAILED. The model did not produce the correct program for this trivial case.\")\n",
    "    print(\"If this fails after training, it suggests a problem with the training process itself, such as:\")\n",
    "    print(\"  - Not enough training data or epochs (the model is still severely undertrained).\")\n",
    "    print(\"  - The learning rate is too high or too low, preventing effective learning.\")\n",
    "    print(\"  - A subtle bug in the `preprocess_function` is creating bad training examples.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"      FINQA SANITY CHECK COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a4f45d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  RUNNING A SUPER SIMPLE SANITY CHECK (NO TRAINING NEEDED)\n",
      "============================================================\n",
      "This test checks if the base T5 model is loaded and working correctly.\n",
      "It uses a simple translation task that T5 can do without fine-tuning.\n",
      "\n",
      "[INFO] Feeding this input to the model:\n",
      "'translate English to German: Hello, how are you?'\n",
      "\n",
      "--- RESULTS ---\n",
      "  [A REASONABLE EXPECTED OUTPUT]: Hallo, wie geht es Ihnen?\n",
      "  [MODEL'S ACTUAL OUTPUT]:      Hallo, wie sind Sie?\n",
      "------------------------------\n",
      "\n",
      "[ANALYSIS]: FAILED. The model did not produce the expected translation.\n",
      "If this fails, there is a fundamental problem with how the model is being loaded from the local path, or the files themselves are corrupt.\n",
      "Please double-check the `model_load_path` and the contents of the model directory.\n",
      "\n",
      "============================================================\n",
      "      SUPER SIMPLE SANITY CHECK COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Super Simple \"No-Training-Required\" Sanity Check ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  RUNNING A SUPER SIMPLE SANITY CHECK (NO TRAINING NEEDED)\")\n",
    "print(\"=\"*60)\n",
    "print(\"This test checks if the base T5 model is loaded and working correctly.\")\n",
    "print(\"It uses a simple translation task that T5 can do without fine-tuning.\")\n",
    "\n",
    "# 1. Define a standard T5 translation prompt\n",
    "# T5 was pre-trained on tasks like this.\n",
    "translation_prompt = \"translate English to German: Hello, how are you?\"\n",
    "\n",
    "# 2. Define the expected, reasonable output\n",
    "# The exact output can vary slightly, but it should be a correct translation.\n",
    "expected_german_translation = \"Hallo, wie geht es Ihnen?\"\n",
    "\n",
    "print(f\"\\n[INFO] Feeding this input to the model:\\n'{translation_prompt}'\")\n",
    "\n",
    "# 3. Use the model to generate the text\n",
    "# Ensure the model and tokenizer are the ones loaded in your script.\n",
    "input_ids = tokenizer(translation_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "outputs = model.generate(input_ids, max_length=128)\n",
    "predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 4. Show the results\n",
    "print(\"\\n--- RESULTS ---\")\n",
    "print(f\"  [A REASONABLE EXPECTED OUTPUT]: {expected_german_translation}\")\n",
    "print(f\"  [MODEL'S ACTUAL OUTPUT]:      {predicted_text}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 5. Analyze the result\n",
    "if \"Hallo\" in predicted_text and \"geht\" in predicted_text:\n",
    "    print(\"\\n[ANALYSIS]: SUCCESS! The model produced a correct German translation.\")\n",
    "    print(\"This confirms that:\")\n",
    "    print(\"  - The T5 model from Hugging Face was loaded correctly.\")\n",
    "    print(\"  - The tokenizer is working.\")\n",
    "    print(\"  - The `model.generate()` function is executing properly.\")\n",
    "    print(\"\\nThis strongly implies that the previous failures are due to the model NOT being fine-tuned on the FinQA task.\")\n",
    "else:\n",
    "    print(\"\\n[ANALYSIS]: FAILED. The model did not produce the expected translation.\")\n",
    "    print(\"If this fails, there is a fundamental problem with how the model is being loaded from the local path, or the files themselves are corrupt.\")\n",
    "    print(\"Please double-check the `model_load_path` and the contents of the model directory.\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"      SUPER SIMPLE SANITY CHECK COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
